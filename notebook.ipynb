{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZizZu94/nlu-second-assignment/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff_g7KO4jncR"
      },
      "source": [
        "# **[NLU] Second Assignment** \n",
        "*   **Zihadul Azam**\n",
        "*   Id: 221747\n",
        "*   zihadul.azam@studenti.unitn.it\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4CIIOKwiP2c"
      },
      "source": [
        "# **Requirements**\n",
        "\n",
        "\n",
        "*   SpaCy: run `pip install spacy`\n",
        "*   Numpy: run `pip install numpy`\n",
        "*   Pandas: run `pip install pandas`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IstODjTEji7U"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.tokens import Doc, Span\n",
        "import conll\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from collections import defaultdict"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA34FO_4qqBl"
      },
      "source": [
        "# **Load Data and Pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rcUm2ZSg-BQ"
      },
      "source": [
        "Load pre-trained language model and set **White-space tokenizer**.\n",
        "\n",
        "Spacy default tokenizer is not good for Conll2003 data set. For example if the input is `+33456` spacy tokenize this string in two tokens: `+` and `33456`, but Conll2003 data set see this as one whole token: `+33456`.\n",
        "So White-space tokenizer was needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3WMxOpWg1xt"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "class WhitespaceTokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words = text.split(\" \")\n",
        "        return Doc(self.vocab, words=words)\n",
        "\n",
        "# set tokenizer\n",
        "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZNmI2DAjz6H"
      },
      "source": [
        "#### **Global vars**\n",
        "\n",
        "Conll2003 data set files path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IVP_lysj4zW"
      },
      "source": [
        "data_folder_path = './data'\n",
        "train_path = data_folder_path + '/train.txt'\n",
        "test_path = data_folder_path + '/test.txt'"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Okb0VMkBOF"
      },
      "source": [
        "#### **Load input data**\n",
        "Load **Conll2003** data set from the file and pre-process.\n",
        "\n",
        "Here we read data from the input file and store them into a dictionary. For every sentence we store only the tokens and respective `entity` with `IOB`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7vnghqXkKbJ"
      },
      "source": [
        "def load_conll_file(path):\n",
        "    OUTPUT_DATA = []\n",
        "    # open file\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        data = f.read()\n",
        "    sentences = data.split('\\n\\n')\n",
        "    for sent in sentences:\n",
        "        sentence = []\n",
        "        ents = []\n",
        "        tokens = sent.split('\\n')\n",
        "\n",
        "        if tokens[0] != '-DOCSTART- -X- -X- O' and tokens[0] != '':\n",
        "            for x in tokens:\n",
        "                x_split = x.split()\n",
        "                # if not short length\n",
        "                if len(x) > 0 and len(x_split) >= 3:\n",
        "                    word = x_split[0].strip()\n",
        "                    if len(word) > 0:\n",
        "                        sentence.append(word)\n",
        "                        try:\n",
        "                            ent = x_split[-1] #get ent\n",
        "                        except IndexError:\n",
        "                            print('Index Error: ', x_split)\n",
        "                        ents.append((word, ent)) # append word with its ent\n",
        "\n",
        "            processed_sentence = ' '.join(sentence)\n",
        "            OUTPUT_DATA.append((processed_sentence, {'entities': ents}))\n",
        "\n",
        "    print('Done getting data !')\n",
        "    print('There are %d sentences.' % (len(sentences)))\n",
        "    return OUTPUT_DATA"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09CP3f7_lROM",
        "outputId": "f038f7ea-8834-4af4-8bc1-a07aa3263374"
      },
      "source": [
        "# load conll2003 test data\n",
        "conll_test_data = load_conll_file(test_path)\n",
        "\n",
        "print('\\n')\n",
        "print('----- Sample data: first 2 sentences -----')\n",
        "for k in conll_test_data[:2]:\n",
        "    print('Sentence: ', k[0])\n",
        "    print('Entities:')\n",
        "    for e in k[1]['entities']:\n",
        "        print(e[0], '|', e[1])\n",
        "\n",
        "    print('************************************')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done getting data !\n",
            "There are 3685 sentences.\n",
            "\n",
            "\n",
            "----- Sample data: first 2 sentences -----\n",
            "Sentence:  SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
            "Entities:\n",
            "SOCCER | O\n",
            "- | O\n",
            "JAPAN | B-LOC\n",
            "GET | O\n",
            "LUCKY | O\n",
            "WIN | O\n",
            ", | O\n",
            "CHINA | B-PER\n",
            "IN | O\n",
            "SURPRISE | O\n",
            "DEFEAT | O\n",
            ". | O\n",
            "************************************\n",
            "Sentence:  Nadim Ladki\n",
            "Entities:\n",
            "Nadim | B-PER\n",
            "Ladki | I-PER\n",
            "************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJlxoMSSkYMr"
      },
      "source": [
        "**Mapper**\n",
        "\n",
        "Spacy entity tags are different w.r.t to Conll2003 tags. Moreover, Conll2003 data set has only 4 types of entity: `ORG, LOC, PER, MISC`.\n",
        "\n",
        "So we need a mapper to map Spacy entity to Conll2003 entity, if we want to compare them and evaluate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9edtYHD2kdVX"
      },
      "source": [
        "def convert_spacy_entity_to_conll(iob, type):\n",
        "    mapper = {\n",
        "        'PERSON': 'PER',\n",
        "        'NORP': 'MISC',\n",
        "        'FAC': 'MISC',\n",
        "        'ORG': 'ORG',\n",
        "        'GPE': 'LOC',\n",
        "        'LOC': 'LOC',\n",
        "        'PRODUCT': 'MISC',\n",
        "        'EVENT': 'MISC',\n",
        "        'WORK_OF_ART': 'MISC',\n",
        "        'LAW': 'MISC',\n",
        "        'LANGUAGE': 'MISC'\n",
        "    }\n",
        "\n",
        "    if not type in mapper:\n",
        "        return 'O'\n",
        "    return iob + '-' + mapper[type]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfDx-Kybke1O"
      },
      "source": [
        "This function for each sentence returns **real entities** and **predicted entities** (with IOB)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXEpJrEckkkz"
      },
      "source": [
        "def get_refs_hyps(data):\n",
        "    refs = [] # real entity from Conll2003 data set\n",
        "    hyps = [] # hypothesis/predicted entity using Spacy\n",
        "\n",
        "    for sent in data:\n",
        "        # get entities of this sentence\n",
        "        entities = sent[1]['entities']\n",
        "        hyp = [] # hypothesis/predicted entity list of the sentence\n",
        "        \n",
        "        doc = nlp(sent[0])\n",
        "        for token in doc:\n",
        "          # get predicted entity\n",
        "          conll_entity = convert_spacy_entity_to_conll(\n",
        "                token.ent_iob_, token.ent_type_)\n",
        "          # add predicted entity to the list\n",
        "          hyp.append((token.text, conll_entity))\n",
        "\n",
        "        # add real entities of this sentence\n",
        "        sent_refs = [(entity[0], entity[1]) for entity in entities]\n",
        "        refs.append(sent_refs)\n",
        "        # add predicted entities of this sentence\n",
        "        hyps.append(hyp)\n",
        "    return refs, hyps"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rhtS6iMmE1m",
        "outputId": "66565932-8c63-4603-f6a7-610b8052f685"
      },
      "source": [
        "print('----- Sample get_refs_hyps(data): first 2 sentences -----')\n",
        "test_refs, test_hyps = get_refs_hyps(conll_test_data[:2])\n",
        "print(\"--> refs list:\")\n",
        "print(*test_refs, sep='\\n')\n",
        "print('\\n')\n",
        "print(\"--> hyps list:\")\n",
        "print(*test_hyps, sep='\\n')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Sample get_refs_hyps(data): first 2 sentences -----\n",
            "--> refs list:\n",
            "[('SOCCER', 'O'), ('-', 'O'), ('JAPAN', 'B-LOC'), ('GET', 'O'), ('LUCKY', 'O'), ('WIN', 'O'), (',', 'O'), ('CHINA', 'B-PER'), ('IN', 'O'), ('SURPRISE', 'O'), ('DEFEAT', 'O'), ('.', 'O')]\n",
            "[('Nadim', 'B-PER'), ('Ladki', 'I-PER')]\n",
            "\n",
            "\n",
            "--> hyps list:\n",
            "[('SOCCER', 'O'), ('-', 'O'), ('JAPAN', 'O'), ('GET', 'O'), ('LUCKY', 'O'), ('WIN', 'B-ORG'), (',', 'O'), ('CHINA', 'B-LOC'), ('IN', 'O'), ('SURPRISE', 'O'), ('DEFEAT', 'O'), ('.', 'O')]\n",
            "[('Nadim', 'O'), ('Ladki', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCR0rUctzn47"
      },
      "source": [
        "We can see here that the Spacy entitis have been converted correctly and we can see already that they don't match always:\n",
        "* Refs list has: `('JAPAN', 'B-LOC')`\n",
        "* Hyps list has: `('JAPAN', 'O')`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvyHgB7qpLMK"
      },
      "source": [
        "# **Task 1** Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
        "\n",
        "* report token-level performance (per class and total)\n",
        " * accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n",
        "* report CoNLL chunk-level performance (per class and total);\n",
        " * precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC0D8MqZkoDL"
      },
      "source": [
        "> ## **Task 1.1** Report token-level performance (per class and total)\n",
        "Accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN9I-fmDrtlM"
      },
      "source": [
        "# get refs and hyps list of the file Conll2003 Test\n",
        "refs, hyps = get_refs_hyps(conll_test_data)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH1NCAN70rKl"
      },
      "source": [
        "Get confusion matrix using scikit-learn metrics `confusion_matrix` function\n",
        "\n",
        "* First we have to create two lists: one with all real entity values and other with predicted entity values\n",
        "\n",
        "* Then we feed these two flat lists to the `confusion_matrix` function of scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "yvdfYovukrY8",
        "outputId": "fcd658e2-9f79-4158-a554-c34e4f4b8479"
      },
      "source": [
        "# create flat real values and predicted values lists\n",
        "entity_refs = []\n",
        "for sent in refs:\n",
        "    for token in sent:\n",
        "        entity_refs.append(token[1])\n",
        "\n",
        "entity_hyps = []\n",
        "for sent in hyps:\n",
        "    for token in sent:\n",
        "        entity_hyps.append(token[1])\n",
        "\n",
        "# get confusion_matrix\n",
        "labels = np.unique(entity_refs)\n",
        "conf_mat = confusion_matrix(entity_refs, entity_hyps, labels=labels)\n",
        "# print confusion matrix\n",
        "pd_table = pd.DataFrame(conf_mat, index=labels, columns=labels)\n",
        "display(pd_table)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B-LOC</th>\n",
              "      <th>B-MISC</th>\n",
              "      <th>B-ORG</th>\n",
              "      <th>B-PER</th>\n",
              "      <th>I-LOC</th>\n",
              "      <th>I-MISC</th>\n",
              "      <th>I-ORG</th>\n",
              "      <th>I-PER</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-LOC</th>\n",
              "      <td>1129</td>\n",
              "      <td>30</td>\n",
              "      <td>143</td>\n",
              "      <td>52</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>6</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MISC</th>\n",
              "      <td>19</td>\n",
              "      <td>396</td>\n",
              "      <td>48</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>178</td>\n",
              "      <td>36</td>\n",
              "      <td>558</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>24</td>\n",
              "      <td>619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PER</th>\n",
              "      <td>50</td>\n",
              "      <td>28</td>\n",
              "      <td>168</td>\n",
              "      <td>989</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>49</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LOC</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MISC</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>94</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>17</td>\n",
              "      <td>464</td>\n",
              "      <td>99</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PER</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>80</td>\n",
              "      <td>887</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>53</td>\n",
              "      <td>64</td>\n",
              "      <td>189</td>\n",
              "      <td>63</td>\n",
              "      <td>32</td>\n",
              "      <td>46</td>\n",
              "      <td>279</td>\n",
              "      <td>163</td>\n",
              "      <td>37434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        B-LOC  B-MISC  B-ORG  B-PER  I-LOC  I-MISC  I-ORG  I-PER      O\n",
              "B-LOC    1129      30    143     52     26       2     40      6    240\n",
              "B-MISC     19     396     48     23      2      26     13      1    174\n",
              "B-ORG     178      36    558    150      0       2     94     24    619\n",
              "B-PER      50      28    168    989      0       1     25     49    307\n",
              "I-LOC       3       0      0      0    130       5     50      7     62\n",
              "I-MISC      0       6      4      1      8      94     34      6     63\n",
              "I-ORG      11       4      6      4     33      17    464     99    197\n",
              "I-PER       1       0      2      7     20       9     80    887    150\n",
              "O          53      64    189     63     32      46    279    163  37434"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLItGQec0u_u"
      },
      "source": [
        "Calculate accuracy per class and overall accuracy\n",
        "\n",
        "$Accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVa-Y5jB0wWR"
      },
      "source": [
        "def get_accuracy_per_class(confusion_matrix, class_labels):\n",
        "  \"\"\"\n",
        "  this function takes confusion matrix and class names as input\n",
        "  returns a dict with accuracy per class\n",
        "  \"\"\"\n",
        "  class_accuracies = {}\n",
        "\n",
        "  # Calculate the accuracy for each one of our classes\n",
        "  for idx, cls in enumerate(class_labels):\n",
        "    # True negatives are all the samples that are not our current GT class (not the current row) \n",
        "    # and were not predicted as the current class (not the current column)\n",
        "    true_negatives = np.sum(np.delete(np.delete(confusion_matrix, idx, axis=0), idx, axis=1))\n",
        "    \n",
        "    # True positives are all the samples of our current class that were predicted as such\n",
        "    true_positives = confusion_matrix[idx, idx]\n",
        "    \n",
        "    # The accuracy for the current class is ratio between correct predictions to all predictions\n",
        "    class_accuracies[cls] = (true_positives + true_negatives) / np.sum(confusion_matrix)\n",
        "  return class_accuracies"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GqAxTcb2SZD"
      },
      "source": [
        "Print accuracy per class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "tHmExlDq2NAY",
        "outputId": "d6a5bdc2-a3a8-42c4-91c6-ad625cc81cc5"
      },
      "source": [
        "# get accuracy per class\n",
        "accuracies_per_clas = get_accuracy_per_class(conf_mat, labels)\n",
        "# print accuracy per class\n",
        "accuracy_pd_table = pd.DataFrame().from_dict(accuracies_per_clas, orient='index')\n",
        "accuracy_pd_table.columns = ['Accuracy']\n",
        "display(accuracy_pd_table.round(3))\n",
        "\n",
        "# print overall accuracy (sum_accurecies_all_classes / num_classes), simple mean of all classes\n",
        "overall_acc = (np.sum(accuracy_pd_table) / len(accuracy_pd_table))\n",
        "print('\\n')\n",
        "print('> Overall accuracy: {}'.format(np.format_float_positional(overall_acc, 3)))\n",
        "print('> Overall accuracy in percentage: {} %'.format(np.format_float_positional(overall_acc*100, 3)))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-LOC</th>\n",
              "      <td>0.982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MISC</th>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>0.964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PER</th>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LOC</th>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MISC</th>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PER</th>\n",
              "      <td>0.987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>0.942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Accuracy\n",
              "B-LOC      0.982\n",
              "B-MISC     0.990\n",
              "B-ORG      0.964\n",
              "B-PER      0.980\n",
              "I-LOC      0.995\n",
              "I-MISC     0.995\n",
              "I-ORG      0.979\n",
              "I-PER      0.987\n",
              "O          0.942"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> Overall accuracy: 0.979\n",
            "> Overall accuracy in percentage: 97.916 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwkSsOIBGHDv"
      },
      "source": [
        "> **Extra:** other metrices using sci-kit learn `classification_report`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "o7-MauMMGMDe",
        "outputId": "542d1235-3f79-4a16-c658-142c68b9abea"
      },
      "source": [
        "class_report = classification_report(entity_refs, entity_hyps, target_names=labels, output_dict=True)\n",
        "# print confusion matrix\n",
        "pd_table = pd.DataFrame(class_report)\n",
        "display(pd_table.round(3))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B-LOC</th>\n",
              "      <th>B-MISC</th>\n",
              "      <th>B-ORG</th>\n",
              "      <th>B-PER</th>\n",
              "      <th>I-LOC</th>\n",
              "      <th>I-MISC</th>\n",
              "      <th>I-ORG</th>\n",
              "      <th>I-PER</th>\n",
              "      <th>O</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.782</td>\n",
              "      <td>0.702</td>\n",
              "      <td>0.499</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.954</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.648</td>\n",
              "      <td>0.901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.677</td>\n",
              "      <td>0.564</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.612</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.435</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.726</td>\n",
              "      <td>0.626</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0.681</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.740</td>\n",
              "      <td>0.965</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.621</td>\n",
              "      <td>0.902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1668.000</td>\n",
              "      <td>702.000</td>\n",
              "      <td>1661.000</td>\n",
              "      <td>1617.000</td>\n",
              "      <td>257.000</td>\n",
              "      <td>216.000</td>\n",
              "      <td>835.000</td>\n",
              "      <td>1156.000</td>\n",
              "      <td>38323.000</td>\n",
              "      <td>0.906</td>\n",
              "      <td>46435.000</td>\n",
              "      <td>46435.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              B-LOC   B-MISC     B-ORG  ...  accuracy  macro avg  weighted avg\n",
              "precision     0.782    0.702     0.499  ...     0.906      0.648         0.901\n",
              "recall        0.677    0.564     0.336  ...     0.906      0.603         0.906\n",
              "f1-score      0.726    0.626     0.402  ...     0.906      0.621         0.902\n",
              "support    1668.000  702.000  1661.000  ...     0.906  46435.000     46435.000\n",
              "\n",
              "[4 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUsUdp5QkIPd"
      },
      "source": [
        "We can see here that the classification_report has a lower total accuracy w.r.t my Overall accuracy calculated above.\n",
        "\n",
        "I think they are different metrices, **Scikit Learn classification report**  contains the simple accuracy, which does not consider **TN** cases:\n",
        "* classification report accuracy = $\\frac{TP}{TP+TN+FP+FN}$\n",
        "\n",
        "So to test, this time I calculated accuracy without considering **TN**, from my confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euaIYj-7ml4w",
        "outputId": "48260423-3455-4dae-ddc4-a6a3d25e0cfb"
      },
      "source": [
        "total_predictions = conf_mat.sum().sum()\n",
        "total_correct_pred = np.diag(conf_mat).sum() # sum of the diagonal of the confusion matrix is equal to TP\n",
        "test_accuracy = total_correct_pred / total_predictions\n",
        "\n",
        "print('Total predictions: ', total_predictions)\n",
        "print('Correct predictions: ', total_correct_pred)\n",
        "print('Accuracy (Correct predictions / Total predictions): ', test_accuracy)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total predictions:  46435\n",
            "Correct predictions:  42081\n",
            "Accuracy (Correct predictions / Total predictions):  0.9062345213739637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7cRllO8pAgy"
      },
      "source": [
        "Here we can see that, my hypothesis was right.\n",
        "So, **Scikit Learn classification report** calculate the simple accuracy, without considering **TN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L2gE-t7o_3U"
      },
      "source": [
        "> ## **Task 1.1** Report CoNLL chunk-level performance (per class and total);\n",
        "Precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW54Wvi_5N1m"
      },
      "source": [
        "Here we use the evaluate function of the provided `conll.py` file to evaluate chunk-level performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DfIs6k4go-ov",
        "outputId": "cbde2601-a450-4f97-d79a-9f17ec012ed7"
      },
      "source": [
        "accuracy = conll.evaluate(refs, hyps)\n",
        "\n",
        "table = pd.DataFrame().from_dict(accuracy, orient='index')\n",
        "display(table.round(3))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.441</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.355</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.724</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.642</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.771</td>\n",
              "      <td>0.668</td>\n",
              "      <td>0.716</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.681</td>\n",
              "      <td>0.547</td>\n",
              "      <td>0.607</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.662</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.581</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "ORG    0.441  0.297  0.355  1661\n",
              "PER    0.724  0.577  0.642  1617\n",
              "LOC    0.771  0.668  0.716  1668\n",
              "MISC   0.681  0.547  0.607   702\n",
              "total  0.662  0.518  0.581  5648"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yJPejzRDSBj"
      },
      "source": [
        "# **Task 2**: Grouping of Entities\n",
        "Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ_aNkwZ5n-P"
      },
      "source": [
        "def get_tokens_indexes(token_list):\n",
        "  \"\"\"\n",
        "    this function returns the unique set of tokens id\n",
        "  \"\"\"\n",
        "  return set([tok.i for tok in token_list])"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ItBCaKO51Zh"
      },
      "source": [
        "This function returns Groups of entities (GOE) of a sentence, the input of the function is a `doc `object, created from a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUccu7ICDUMs"
      },
      "source": [
        "def get_doc_GOE(doc: spacy.tokens.Doc):\n",
        "  \"\"\"\n",
        "    this function takes a doc as input\n",
        "    returns list of entities groups of Doc\n",
        "  \"\"\"\n",
        "  # entity list of each chunk (if has any)\n",
        "  chunk_ents_list = defaultdict(lambda:[])\n",
        "  unassigned = []\n",
        "\n",
        "  for ent in doc.ents:\n",
        "    ent_indexes = get_tokens_indexes(ent) # all token ids of the entity\n",
        "    found = False\n",
        "\n",
        "    # check if this ent is part of a chunk\n",
        "    for i, chunk in enumerate(doc.noun_chunks):\n",
        "      chunk_indexs = get_tokens_indexes(chunk) # all token ids of the chunk\n",
        "      \n",
        "      # if any token of the entity is part of the noun chunk\n",
        "      if len(ent_indexes.intersection(chunk_indexs)) > 0:\n",
        "        chunk_ents_list[i].append(ent[0].ent_type_)\n",
        "        found = True\n",
        "\n",
        "    # if this ent is not part of a chunk add to the unassigned list\n",
        "    # so, this ent does not create any group with multiple ents,\n",
        "    # it creates a group alone\n",
        "    if not found:\n",
        "      unassigned.append(ent[0].ent_type_)\n",
        "\n",
        "  # join chunk_ents_list and unassigned list togather and return\n",
        "  return [ents for _, ents in chunk_ents_list.items()] + [[u] for u in unassigned]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqodZmiQ6MEA"
      },
      "source": [
        "Combine all entity groups of all sentences and show the frequency for each group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKGszk3j6NpQ"
      },
      "source": [
        "def grouping_of_entities_freq(data):\n",
        "  \"\"\"\n",
        "    this function takes a corpus as input\n",
        "    return frequency of all groups of entities\n",
        "  \"\"\"\n",
        "  # init result list\n",
        "  result = defaultdict(lambda:0)\n",
        "\n",
        "  for sent in data:\n",
        "      doc = nlp(sent[0])\n",
        "      # get doc group of entities (GOE)\n",
        "      doc_GOE = get_doc_GOE(doc)\n",
        "      # update frequencies in result dictionary\n",
        "      for group in doc_GOE:\n",
        "        result['-'.join(group)] += 1\n",
        "  return result\n",
        "\n",
        "# get frequency of groups\n",
        "group_entities_frequency = grouping_of_entities_freq(conll_test_data)\n",
        "# sort by frequency (most frequent on the top)\n",
        "group_entities_frequency = dict(sorted(group_entities_frequency.items(), key=lambda item: item[1], reverse=True))"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWbSlHIC7_DK"
      },
      "source": [
        "Print top 40 frequent groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TEnkbtjZtY3",
        "outputId": "18041fc1-6ebd-44bc-c4a9-b18fa2d160b1"
      },
      "source": [
        "print('----- Grouping of Entities frequency (top 40) -----')\n",
        "for key, value in list(group_entities_frequency.items())[:40]:\n",
        "  print(key, ': ', value)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Grouping of Entities frequency (top 40) -----\n",
            "CARDINAL :  1821\n",
            "GPE :  1267\n",
            "PERSON :  1050\n",
            "ORG :  1043\n",
            "DATE :  953\n",
            "NORP :  302\n",
            "MONEY :  148\n",
            "ORDINAL :  115\n",
            "TIME :  104\n",
            "CARDINAL-PERSON :  91\n",
            "PERCENT :  87\n",
            "QUANTITY :  81\n",
            "EVENT :  64\n",
            "LOC :  53\n",
            "NORP-PERSON :  45\n",
            "PRODUCT :  29\n",
            "ORG-PERSON :  28\n",
            "GPE-PERSON :  25\n",
            "CARDINAL-ORG :  21\n",
            "FAC :  19\n",
            "CARDINAL-GPE :  18\n",
            "CARDINAL-NORP :  17\n",
            "PERSON-PERSON :  13\n",
            "WORK_OF_ART :  13\n",
            "GPE-ORG :  11\n",
            "PERSON-GPE :  10\n",
            "LAW :  10\n",
            "DATE-EVENT :  9\n",
            "ORG-ORG :  9\n",
            "GPE-GPE :  9\n",
            "LANGUAGE :  7\n",
            "NORP-ORG :  6\n",
            "ORG-GPE :  5\n",
            "DATE-ORG :  5\n",
            "DATE-TIME :  5\n",
            "DATE-NORP :  5\n",
            "ORG-DATE :  5\n",
            "DATE-PERSON :  3\n",
            "PERSON-ORG :  3\n",
            "GPE-ORDINAL :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwVjyZoHcVEI"
      },
      "source": [
        "**Extra test**: calculate frequency by class number of group\n",
        "\n",
        "> example: `\"CARDINAL-NORP\"` is built with 2 classes or entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_HYrFVMcxx-",
        "outputId": "05f71015-e51f-49f0-a558-f0a0b3c1e371"
      },
      "source": [
        "class_num_freq = defaultdict(lambda:0)\n",
        "for key, value in group_entities_frequency.items():\n",
        "  classes = key.split('-')\n",
        "  class_num_freq[len(classes)] += value\n",
        "\n",
        "print('----- Frequency by number of classes -----')\n",
        "for key, value in class_num_freq.items():\n",
        "  print('Group with ', key, ' class: ', value)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Frequency by number of classes -----\n",
            "Group with  1  class:  7166\n",
            "Group with  2  class:  405\n",
            "Group with  3  class:  20\n",
            "Group with  4  class:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8amPNu9p6DP"
      },
      "source": [
        "Here we can see that, the group with 1 entity/class is most frequent and only 3 entries for group made by 4 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gvuDb7FYlEn"
      },
      "source": [
        "# **Task 3**: Post-processing \n",
        "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation.\n",
        "\n",
        "Here the idea is:\n",
        "* for each `entity` of the `doc`, take it's `token list`\n",
        " * then for each `token` (from `token list`) take his `children` and `parent`, We called them togather `family members`\n",
        "   * If a family member has `compund` dependency and empty `entity type`\n",
        "     * Then check if we can extend the `entity type` from the `parent` (if fam member is a children) or from the `child` (if fam member is parent) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAFgdDwkY8_f"
      },
      "source": [
        "def extend_entities(token_list, start, end, ent_type):\n",
        "  \"\"\"\n",
        "  this function update ent_type,\n",
        "  start token has B-ent_type\n",
        "  and rest I-ent_type\n",
        "  \"\"\"\n",
        "  iob = 'B'\n",
        "  for i in range(start, end):\n",
        "      new_ent = convert_spacy_entity_to_conll(iob, ent_type)\n",
        "      text = token_list[i][0] \n",
        "      token_list[i] = (text, new_ent)\n",
        "      if iob == 'B':\n",
        "        iob = 'I'\n",
        "  return token_list\n",
        "\n",
        "def post_processing(doc: spacy.tokens.Doc):\n",
        "  total_changes = 0\n",
        "  result = {}\n",
        "  # init result list\n",
        "  for token in doc:\n",
        "    result[token.i] = (token.text, convert_spacy_entity_to_conll(token.ent_iob_, token.ent_type_))\n",
        "  \n",
        "  # contains ents already processed\n",
        "  already_processed = []\n",
        "\n",
        "  for ent in doc.ents:\n",
        "    # create ent token list, so can be modified this list\n",
        "    ent_token_list = list(ent)\n",
        "    for ent_token in ent_token_list:\n",
        "      # we want to extend the entity to the children and also to the parent\n",
        "      # in both case they can have a compund dependency with this entity\n",
        "      # but without entity for itself,\n",
        "      # so we take as candidate all children\n",
        "      # and also the parent if current entity has dep_ == compound\n",
        "      family_list = list(ent_token.children) + ([ent_token.head] if ent_token.dep_ == 'compund' and ent_token.head.ent_type_ == '' else []) \n",
        "      for fam_member in family_list:\n",
        "        # check if this member is a neighbour\n",
        "        is_neighbour = fam_member.i == ent.start - 1 or fam_member.i == ent.end\n",
        "        # check if this member has compound dep and has empty ent and is neighbour and yet not pre processed      \n",
        "        if fam_member.dep_ == 'compound' and fam_member.ent_type_ == '' and is_neighbour and not fam_member.i in already_processed:\n",
        "          # find start and finish of the current ent \n",
        "          start = min(fam_member.i, ent.start)\n",
        "          end = max(fam_member.i, ent.end)\n",
        "          # extend ent and save into the result list\n",
        "          result = extend_entities(result, start, end, ent_token.ent_type_)\n",
        "          # add this new fam_memeber to the current ent token list, so we can check if\n",
        "          # it has itself any children or parent who needs entity extend\n",
        "          ent_token_list.append(fam_member)\n",
        "          # update count\n",
        "          total_changes += 1\n",
        "          # add to already_processed list\n",
        "          already_processed.append(fam_member.i)\n",
        "\n",
        "  return total_changes, [value for _,value in result.items()]"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtSXG_EeY5BO"
      },
      "source": [
        "**Test:** doing test with a single sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHgYZXxyo02r",
        "outputId": "80d2a90a-e2bd-430d-bc00-94b42dc3a3c1"
      },
      "source": [
        "test = \"He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains\"\n",
        "doc = nlp(test)\n",
        "total_changes, result = post_processing(doc)\n",
        "\n",
        "print('------------ Test result -------------')\n",
        "print('Sentence: ', test)\n",
        "print('Text', ' '*(8) ,'Iob-Ent\\tPost-proces')\n",
        "for token in doc:\n",
        "  iob_ent = convert_spacy_entity_to_conll(token.ent_iob_, token.ent_type_)\n",
        "  print(token.text, ' '*(15-len(token.text)) , iob_ent, '\\t', result[token.i][1])\n",
        "\n",
        "print('Total entity changes: ', total_changes)\n",
        "print('Note: Commissioner\\'s ent type has been changed')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------ Test result -------------\n",
            "Sentence:  He said a proposal last month by EU Farm Commissioner Franz Fischler to ban sheep brains\n",
            "Text          Iob-Ent\tPost-proces\n",
            "He               O \t O\n",
            "said             O \t O\n",
            "a                O \t O\n",
            "proposal         O \t O\n",
            "last             O \t O\n",
            "month            O \t O\n",
            "by               O \t O\n",
            "EU               B-ORG \t B-ORG\n",
            "Farm             I-ORG \t I-ORG\n",
            "Commissioner     O \t B-PER\n",
            "Franz            B-PER \t I-PER\n",
            "Fischler         I-PER \t I-PER\n",
            "to               O \t O\n",
            "ban              O \t O\n",
            "sheep            O \t O\n",
            "brains           O \t O\n",
            "Total entity changes:  1\n",
            "Note: Commissioner's ent type has been changed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20C55KMPpT_z",
        "outputId": "999bb0b6-1de6-49c4-9d57-096c8dd54674"
      },
      "source": [
        "post_processing_result = []\n",
        "total_changes = 0\n",
        "\n",
        "for sent in conll_test_data:\n",
        "  doc = nlp(sent[0])\n",
        "  t, res = post_processing(doc)\n",
        "  post_processing_result.append(res)\n",
        "  total_changes += t\n",
        "\n",
        "print('Total entity changes: ', total_changes)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total entity changes:  344\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "E__ePsFGqzJC",
        "outputId": "ab8b2038-70e4-4706-9a3a-ec3c413960d4"
      },
      "source": [
        "accuracy = conll.evaluate(refs, post_processing_result)\n",
        "\n",
        "table = pd.DataFrame().from_dict(accuracy, orient='index')\n",
        "display(table.round(3))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.428</td>\n",
              "      <td>0.288</td>\n",
              "      <td>0.345</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.585</td>\n",
              "      <td>0.466</td>\n",
              "      <td>0.519</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.754</td>\n",
              "      <td>0.653</td>\n",
              "      <td>0.700</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.679</td>\n",
              "      <td>0.546</td>\n",
              "      <td>0.605</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.613</td>\n",
              "      <td>0.479</td>\n",
              "      <td>0.538</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "ORG    0.428  0.288  0.345  1661\n",
              "PER    0.585  0.466  0.519  1617\n",
              "LOC    0.754  0.653  0.700  1668\n",
              "MISC   0.679  0.546  0.605   702\n",
              "total  0.613  0.479  0.538  5648"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqVj7K-hYTxM"
      },
      "source": [
        "Here we can see that, the performances is slightly gone down.\n",
        "\n",
        "Before post-processing the performance was:\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    }
  ]
}