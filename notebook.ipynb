{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZizZu94/nlu-second-assignment/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff_g7KO4jncR"
      },
      "source": [
        "# **[NLU] Second Assignment** \n",
        "*   **Zihadul Azam**\n",
        "*   Id: 221747\n",
        "*   zihadul.azam@studenti.unitn.it\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE0k7yO7jVyu"
      },
      "source": [
        "Commands to set Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viBTfFZihwGR",
        "outputId": "384dedc3-2909-43dd-bf5d-c3a7803aeb4c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiyDkSqaieap"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/drive/My Drive/Colab Notebooks/nlu/second-assignment/nlu-second-assignment')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-nQ-DDtk3jH",
        "outputId": "3fa61907-e577-40b8-8f9b-59d17bc1bd1c"
      },
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/nlu/second-assignment/nlu-second-assignment"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/nlu/second-assignment/nlu-second-assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EH4Sos_lSm1",
        "outputId": "b8cc13eb-ceb4-495a-83f9-06bc24e3f6cc"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/nlu/second-assignment/nlu-second-assignment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4CIIOKwiP2c"
      },
      "source": [
        "# **Requirements**\n",
        "\n",
        "\n",
        "*   SpaCy: run `pip install spacy`\n",
        "*   Sk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IstODjTEji7U"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "import conll\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "# utils\n",
        "import utils"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rcUm2ZSg-BQ"
      },
      "source": [
        "Load nlp and set white-space tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3WMxOpWg1xt"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "class WhitespaceTokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words = text.split(\" \")\n",
        "        return Doc(self.vocab, words=words)\n",
        "\n",
        "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZNmI2DAjz6H"
      },
      "source": [
        "#### **Global vars**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IVP_lysj4zW"
      },
      "source": [
        "data_folder_path = './data'\n",
        "train_path = data_folder_path + '/train.txt'\n",
        "test_path = data_folder_path + '/test.txt'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Okb0VMkBOF"
      },
      "source": [
        "#### **Load input data**\n",
        "Load conll 2003 data from file and preprocess "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7vnghqXkKbJ"
      },
      "source": [
        "def load_conll_file(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        data = f.read()\n",
        "    sentences = data.split('\\n\\n')\n",
        "    OUTPUT_DATA = []\n",
        "    entities = []\n",
        "    for sent in sentences:\n",
        "        tokens = sent.split('\\n')\n",
        "        sentence = []\n",
        "        ent_sentence_spacy = []\n",
        "        ents = []\n",
        "\n",
        "        if tokens[0] != '-DOCSTART- -X- -X- O' and tokens[0] != '':\n",
        "            for x in tokens:\n",
        "                x_split = x.split()\n",
        "                # if not short length\n",
        "                if len(x) > 0 and len(x_split) >= 3:\n",
        "                    word = x_split[0]\n",
        "                    word = word.strip()\n",
        "\n",
        "                    if len(word) > 0:\n",
        "                        sentence.append(word)\n",
        "                        try:\n",
        "                            ent = x_split[-1]\n",
        "                        except IndexError:\n",
        "                            print('Index Error: ', x_split)\n",
        "                        ents.append((word, ent))\n",
        "                # else:\n",
        "                    #print('Short length x: ', x, ' . Removed.')\n",
        "\n",
        "            processed_sentence = ' '.join(sentence)  # .lower()\n",
        "            OUTPUT_DATA.append((processed_sentence, {'entities': ents}))\n",
        "\n",
        "    print('Done getting data !')\n",
        "    print('There are %d sentences.' % (len(sentences)))\n",
        "    return OUTPUT_DATA"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09CP3f7_lROM",
        "outputId": "dc428b5b-d2e0-42c1-f141-986f2629f3a0"
      },
      "source": [
        "# load conll2003 test data\n",
        "conll_test_data = load_conll_file(test_path)\n",
        "\n",
        "print('\\n')\n",
        "print('----- Sample data: first 2 sentences -----')\n",
        "for k in conll_test_data[:2]:\n",
        "    print('Sentence: ', k[0])\n",
        "    print('Entities:')\n",
        "    for e in k[1]['entities']:\n",
        "        print(e[0], '|', e[1])\n",
        "\n",
        "    print('************************************')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done getting data !\n",
            "There are 3685 sentences.\n",
            "\n",
            "\n",
            "----- Sample data: first 2 sentences -----\n",
            "Sentence:  SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
            "Entities:\n",
            "SOCCER | O\n",
            "- | O\n",
            "JAPAN | B-LOC\n",
            "GET | O\n",
            "LUCKY | O\n",
            "WIN | O\n",
            ", | O\n",
            "CHINA | B-PER\n",
            "IN | O\n",
            "SURPRISE | O\n",
            "DEFEAT | O\n",
            ". | O\n",
            "************************************\n",
            "Sentence:  Nadim Ladki\n",
            "Entities:\n",
            "Nadim | B-PER\n",
            "Ladki | I-PER\n",
            "************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJlxoMSSkYMr"
      },
      "source": [
        "Mapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9edtYHD2kdVX"
      },
      "source": [
        "def convert_spacy_entity_to_conll(iob, type):\n",
        "    mapper = {\n",
        "        'PERSON': 'PER',\n",
        "        'NORP': 'MISC',\n",
        "        'FAC': 'MISC',\n",
        "        'ORG': 'ORG',\n",
        "        'GPE': 'LOC',\n",
        "        'LOC': 'LOC',\n",
        "        'PRODUCT': 'MISC',\n",
        "        'EVENT': 'MISC',\n",
        "        'WORK_OF_ART': 'MISC',\n",
        "        'LAW': 'MISC',\n",
        "        'LANGUAGE': 'MISC'\n",
        "    }\n",
        "\n",
        "    if not type in mapper:\n",
        "        return 'O'\n",
        "    return iob + '-' + mapper[type]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfDx-Kybke1O"
      },
      "source": [
        "For each sentence get real entity and predicted entity (with IOB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXEpJrEckkkz"
      },
      "source": [
        "def get_refs_hyps(data):\n",
        "    refs = []\n",
        "    hyps = []\n",
        "\n",
        "    for sent in data:\n",
        "        # get entities of this sentence\n",
        "        entities = sent[1]['entities']\n",
        "        hyp = []\n",
        "        doc = nlp(sent[0])\n",
        "\n",
        "        for token in doc:\n",
        "          # get predicted entity\n",
        "          conll_entity = convert_spacy_entity_to_conll(\n",
        "                token.ent_iob_, token.ent_type_)\n",
        "          # add predicted entity to the list\n",
        "          hyp.append((token.text, conll_entity))\n",
        "\n",
        "        # add real entities of this sentence\n",
        "        sent_refs = [(entity[0], entity[1]) for entity in entities]\n",
        "        refs.append(sent_refs)\n",
        "        # add predicted entities of this sentence\n",
        "        hyps.append(hyp)\n",
        "    return refs, hyps"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rhtS6iMmE1m",
        "outputId": "9a55a57f-6ef6-4e26-b6b8-a764132be7d1"
      },
      "source": [
        "print('----- Sample get_refs_hyps(data): first 2 sentences -----')\n",
        "test_refs, test_hyps = get_refs_hyps(conll_test_data[:2])\n",
        "print(\"--> refs list:\")\n",
        "print(*test_refs, sep='\\n')\n",
        "print('\\n')\n",
        "print(\"--> hyps list:\")\n",
        "print(*test_hyps, sep='\\n')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Sample get_refs_hyps(data): first 2 sentences -----\n",
            "--> refs list:\n",
            "[('SOCCER', 'O'), ('-', 'O'), ('JAPAN', 'B-LOC'), ('GET', 'O'), ('LUCKY', 'O'), ('WIN', 'O'), (',', 'O'), ('CHINA', 'B-PER'), ('IN', 'O'), ('SURPRISE', 'O'), ('DEFEAT', 'O'), ('.', 'O')]\n",
            "[('Nadim', 'B-PER'), ('Ladki', 'I-PER')]\n",
            "\n",
            "\n",
            "--> hyps list:\n",
            "[('SOCCER', 'O'), ('-', 'O'), ('JAPAN', 'O'), ('GET', 'O'), ('LUCKY', 'O'), ('WIN', 'B-ORG'), (',', 'O'), ('CHINA', 'B-LOC'), ('IN', 'O'), ('SURPRISE', 'O'), ('DEFEAT', 'O'), ('.', 'O')]\n",
            "[('Nadim', 'O'), ('Ladki', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvyHgB7qpLMK"
      },
      "source": [
        "# **Task 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC0D8MqZkoDL"
      },
      "source": [
        "> ## **Task 1.1**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN9I-fmDrtlM"
      },
      "source": [
        "# get refs and hyps\n",
        "refs, hyps = get_refs_hyps(conll_test_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH1NCAN70rKl"
      },
      "source": [
        "Get confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "yvdfYovukrY8",
        "outputId": "69790138-9bd7-477c-a097-fe67e2013e8d"
      },
      "source": [
        "# create flat real values list and predicted values lists\n",
        "entity_refs = []\n",
        "for sent in refs:\n",
        "    for token in sent:\n",
        "        entity_refs.append(token[1])\n",
        "\n",
        "entity_hyps = []\n",
        "for sent in hyps:\n",
        "    for token in sent:\n",
        "        entity_hyps.append(token[1])\n",
        "\n",
        "# get confusion_matrix\n",
        "labels = np.unique(entity_refs)\n",
        "conf_mat = confusion_matrix(entity_refs, entity_hyps, labels=labels)\n",
        "# print confusion matrix\n",
        "pd_table = pd.DataFrame(conf_mat, index=labels, columns=labels)\n",
        "display(pd_table)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B-LOC</th>\n",
              "      <th>B-MISC</th>\n",
              "      <th>B-ORG</th>\n",
              "      <th>B-PER</th>\n",
              "      <th>I-LOC</th>\n",
              "      <th>I-MISC</th>\n",
              "      <th>I-ORG</th>\n",
              "      <th>I-PER</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-LOC</th>\n",
              "      <td>1129</td>\n",
              "      <td>30</td>\n",
              "      <td>143</td>\n",
              "      <td>52</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>40</td>\n",
              "      <td>6</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MISC</th>\n",
              "      <td>19</td>\n",
              "      <td>396</td>\n",
              "      <td>48</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>178</td>\n",
              "      <td>36</td>\n",
              "      <td>558</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>24</td>\n",
              "      <td>619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PER</th>\n",
              "      <td>50</td>\n",
              "      <td>28</td>\n",
              "      <td>168</td>\n",
              "      <td>989</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>49</td>\n",
              "      <td>307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LOC</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MISC</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>94</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>17</td>\n",
              "      <td>464</td>\n",
              "      <td>99</td>\n",
              "      <td>197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PER</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>80</td>\n",
              "      <td>887</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>53</td>\n",
              "      <td>64</td>\n",
              "      <td>189</td>\n",
              "      <td>63</td>\n",
              "      <td>32</td>\n",
              "      <td>46</td>\n",
              "      <td>279</td>\n",
              "      <td>163</td>\n",
              "      <td>37434</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        B-LOC  B-MISC  B-ORG  B-PER  I-LOC  I-MISC  I-ORG  I-PER      O\n",
              "B-LOC    1129      30    143     52     26       2     40      6    240\n",
              "B-MISC     19     396     48     23      2      26     13      1    174\n",
              "B-ORG     178      36    558    150      0       2     94     24    619\n",
              "B-PER      50      28    168    989      0       1     25     49    307\n",
              "I-LOC       3       0      0      0    130       5     50      7     62\n",
              "I-MISC      0       6      4      1      8      94     34      6     63\n",
              "I-ORG      11       4      6      4     33      17    464     99    197\n",
              "I-PER       1       0      2      7     20       9     80    887    150\n",
              "O          53      64    189     63     32      46    279    163  37434"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLItGQec0u_u"
      },
      "source": [
        "Calculate accuracy per class and overall accuracy\n",
        "\n",
        "$Accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "OVa-Y5jB0wWR",
        "outputId": "b89ec9d6-f192-4dfd-82ee-d6d753558bd5"
      },
      "source": [
        "def get_accuracy_per_class(confusion_matrix, class_labels):\n",
        "  \"\"\"\n",
        "  this function takes confusion matrix and class names in input\n",
        "  return a dict with accuracy per class\n",
        "  \"\"\"\n",
        "  class_accuracies = {}\n",
        "\n",
        "  # Calculate the accuracy for each one of our classes\n",
        "  for idx, cls in enumerate(class_labels):\n",
        "    # True negatives are all the samples that are not our current GT class (not the current row) \n",
        "    # and were not predicted as the current class (not the current column)\n",
        "    true_negatives = np.sum(np.delete(np.delete(confusion_matrix, idx, axis=0), idx, axis=1))\n",
        "    \n",
        "    # True positives are all the samples of our current class that were predicted as such\n",
        "    true_positives = confusion_matrix[idx, idx]\n",
        "    \n",
        "    # The accuracy for the current class is ratio between correct predictions to all predictions\n",
        "    class_accuracies[cls] = (true_positives + true_negatives) / np.sum(confusion_matrix)\n",
        "  return class_accuracies\n",
        "\n",
        "# get accuracy per class\n",
        "accuracies_per_clas = get_accuracy_per_class(conf_mat, labels)\n",
        "# print accuracy per class\n",
        "accuracy_pd_table = pd.DataFrame().from_dict(accuracies_per_clas, orient='index')\n",
        "accuracy_pd_table.columns = ['Accuracy']\n",
        "display(accuracy_pd_table.round(3))\n",
        "\n",
        "# print overall accuracy (sum_accurecies_all_classes / num_classes)\n",
        "overall_acc = (np.sum(accuracy_pd_table) / len(accuracy_pd_table))\n",
        "print('\\n')\n",
        "print('> Overall accuracy: {}'.format(np.format_float_positional(overall_acc, 3)))\n",
        "print('> Overall accuracy in percentage: {} %'.format(np.format_float_positional(overall_acc*100, 3)))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>B-LOC</th>\n",
              "      <td>0.982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-MISC</th>\n",
              "      <td>0.990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ORG</th>\n",
              "      <td>0.964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PER</th>\n",
              "      <td>0.980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-LOC</th>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-MISC</th>\n",
              "      <td>0.995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ORG</th>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PER</th>\n",
              "      <td>0.987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>0.942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Accuracy\n",
              "B-LOC      0.982\n",
              "B-MISC     0.990\n",
              "B-ORG      0.964\n",
              "B-PER      0.980\n",
              "I-LOC      0.995\n",
              "I-MISC     0.995\n",
              "I-ORG      0.979\n",
              "I-PER      0.987\n",
              "O          0.942"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "> Overall accuracy: 0.979\n",
            "> Overall accuracy in percentage: 97.916 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwkSsOIBGHDv"
      },
      "source": [
        "> **Extra:** other metrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "o7-MauMMGMDe",
        "outputId": "05c7d588-578e-4f41-e994-11e5c82e96a8"
      },
      "source": [
        "class_report = classification_report(entity_refs, entity_hyps, target_names=labels, output_dict=True)\n",
        "# print confusion matrix\n",
        "pd_table = pd.DataFrame(class_report)\n",
        "display(pd_table.round(3))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B-LOC</th>\n",
              "      <th>B-MISC</th>\n",
              "      <th>B-ORG</th>\n",
              "      <th>B-PER</th>\n",
              "      <th>I-LOC</th>\n",
              "      <th>I-MISC</th>\n",
              "      <th>I-ORG</th>\n",
              "      <th>I-PER</th>\n",
              "      <th>O</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.782</td>\n",
              "      <td>0.702</td>\n",
              "      <td>0.499</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.430</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.954</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.648</td>\n",
              "      <td>0.901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.677</td>\n",
              "      <td>0.564</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.612</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.435</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.767</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.726</td>\n",
              "      <td>0.626</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0.681</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.740</td>\n",
              "      <td>0.965</td>\n",
              "      <td>0.906</td>\n",
              "      <td>0.621</td>\n",
              "      <td>0.902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1668.000</td>\n",
              "      <td>702.000</td>\n",
              "      <td>1661.000</td>\n",
              "      <td>1617.000</td>\n",
              "      <td>257.000</td>\n",
              "      <td>216.000</td>\n",
              "      <td>835.000</td>\n",
              "      <td>1156.000</td>\n",
              "      <td>38323.000</td>\n",
              "      <td>0.906</td>\n",
              "      <td>46435.000</td>\n",
              "      <td>46435.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              B-LOC   B-MISC     B-ORG  ...  accuracy  macro avg  weighted avg\n",
              "precision     0.782    0.702     0.499  ...     0.906      0.648         0.901\n",
              "recall        0.677    0.564     0.336  ...     0.906      0.603         0.906\n",
              "f1-score      0.726    0.626     0.402  ...     0.906      0.621         0.902\n",
              "support    1668.000  702.000  1661.000  ...     0.906  46435.000     46435.000\n",
              "\n",
              "[4 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUsUdp5QkIPd"
      },
      "source": [
        "We can see here that the classification_report has a lower total accuracy w.r.t my calculated Overall accuracy.\n",
        "I think they are different metrices, **Scikit Learn classification report **contains the simple accuracy, which does not consider **TN** cases:\n",
        "* classification report accuracy = $\\frac{TP}{TP+TN+FP+FN}$\n",
        "\n",
        "so, to test it I calculated it from my confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euaIYj-7ml4w",
        "outputId": "1485f053-00d9-40b5-c69d-52e6278c620d"
      },
      "source": [
        "total_predictions = conf_mat.sum().sum()\n",
        "total_correct_pred = np.diag(conf_mat).sum()\n",
        "test_accuracy = total_correct_pred / total_predictions\n",
        "\n",
        "print('Total predictions: ', total_predictions)\n",
        "print('Correct predictions: ', total_correct_pred)\n",
        "print('Accuracy (Correct predictions / Total predictions): ', test_accuracy)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total predictions:  46435\n",
            "Correct predictions:  42081\n",
            "Accuracy (Correct predictions / Total predictions):  0.9062345213739637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7cRllO8pAgy"
      },
      "source": [
        "Here I can see, that my hypothesis was right.\n",
        "So, **Scikit Learn classification report** calculate the simple accuracy, without considering **TN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L2gE-t7o_3U"
      },
      "source": [
        "> ## **Task 1.1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DfIs6k4go-ov",
        "outputId": "903e3038-5c80-44f8-8720-fb327e375f4c"
      },
      "source": [
        "accuracy = conll.evaluate(refs, hyps)\n",
        "\n",
        "table = pd.DataFrame().from_dict(accuracy, orient='index')\n",
        "display(table.round(3))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f</th>\n",
              "      <th>s</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PER</th>\n",
              "      <td>0.724</td>\n",
              "      <td>0.577</td>\n",
              "      <td>0.642</td>\n",
              "      <td>1617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MISC</th>\n",
              "      <td>0.681</td>\n",
              "      <td>0.547</td>\n",
              "      <td>0.607</td>\n",
              "      <td>702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ORG</th>\n",
              "      <td>0.441</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.355</td>\n",
              "      <td>1661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LOC</th>\n",
              "      <td>0.771</td>\n",
              "      <td>0.668</td>\n",
              "      <td>0.716</td>\n",
              "      <td>1668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total</th>\n",
              "      <td>0.662</td>\n",
              "      <td>0.518</td>\n",
              "      <td>0.581</td>\n",
              "      <td>5648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           p      r      f     s\n",
              "PER    0.724  0.577  0.642  1617\n",
              "MISC   0.681  0.547  0.607   702\n",
              "ORG    0.441  0.297  0.355  1661\n",
              "LOC    0.771  0.668  0.716  1668\n",
              "total  0.662  0.518  0.581  5648"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yJPejzRDSBj"
      },
      "source": [
        "# **Task 2**: Grouping of Entities\n",
        "Write a function to group recognized named entities using noun_chunks method of spaCy. Analyze the groups in terms of most frequent combinations (i.e. NER types that go together)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUccu7ICDUMs"
      },
      "source": [
        "def get_tokens_indexes(token_list):\n",
        "  \"\"\"\n",
        "    this function returns the unique set of token indexes\n",
        "  \"\"\"\n",
        "  return set([tok.i for tok in token_list])\n",
        "\n",
        "\n",
        "def get_doc_GOE(doc: spacy.tokens.Doc):\n",
        "  \"\"\"\n",
        "    this function takes a doc as input\n",
        "    returns list of entities groups of Doc\n",
        "  \"\"\"\n",
        "  # entity list of each chunk (if has any)\n",
        "  chunk_ents_list = defaultdict(lambda:[])\n",
        "  unassigned = []\n",
        "\n",
        "  for ent in doc.ents:\n",
        "    ent_indexes = get_tokens_indexes(ent)\n",
        "    found = False\n",
        "\n",
        "    # check if this ent is part of a chunk\n",
        "    for i, chunk in enumerate(doc.noun_chunks):\n",
        "      chunk_indexs = get_chunk_tokens_indexes(chunk)\n",
        "      if len(ent_indexes.intersection(chunk_indexs)) > 0:\n",
        "        chunk_ents_list[i].append(ent[0].ent_type_)\n",
        "        found = True\n",
        "\n",
        "    # if this ent is not part of a chunk add to unassigned list\n",
        "    if not found:\n",
        "      unassigned.append(ent[0].ent_type_)\n",
        "\n",
        "  # join chunk_ents_list and unassigned list togather and return\n",
        "  return [ents for _, ents in chunk_ents_list.items()] + [[u] for u in unassigned]\n",
        "\n",
        "def grouping_of_entities_freq(data):\n",
        "  \"\"\"\n",
        "    this function takes a corpus as input\n",
        "    return frequency of all groups of entities\n",
        "  \"\"\"\n",
        "  # init result list\n",
        "  result = defaultdict(lambda:0)\n",
        "\n",
        "  for sent in data:\n",
        "      doc = nlp(sent[0])\n",
        "      # get doc group of entities (GOE)\n",
        "      doc_GOE = get_doc_GOE(doc)\n",
        "      # update frequencies in result dictionary\n",
        "      for group in doc_GOE:\n",
        "        result['-'.join(group)] += 1\n",
        "  return result\n",
        "\n",
        "group_entities_frequency = grouping_of_entities_freq(conll_test_data)\n",
        "group_entities_frequency = dict(sorted(group_entities_frequency.items(), key=lambda item: item[1], reverse=True))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TEnkbtjZtY3",
        "outputId": "73f645d2-7bd3-4c56-cd58-38f870550d30"
      },
      "source": [
        "print('----- Grouping of Entities frequency (top 40) -----')\n",
        "for key, value in list(group_entities_frequency.items())[:40]:\n",
        "  print(key, ': ', value)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Grouping of Entities frequency (top 40) -----\n",
            "CARDINAL :  1821\n",
            "GPE :  1267\n",
            "PERSON :  1050\n",
            "ORG :  1043\n",
            "DATE :  953\n",
            "NORP :  302\n",
            "MONEY :  148\n",
            "ORDINAL :  115\n",
            "TIME :  104\n",
            "CARDINAL-PERSON :  91\n",
            "PERCENT :  87\n",
            "QUANTITY :  81\n",
            "EVENT :  64\n",
            "LOC :  53\n",
            "NORP-PERSON :  45\n",
            "PRODUCT :  29\n",
            "ORG-PERSON :  28\n",
            "GPE-PERSON :  25\n",
            "CARDINAL-ORG :  21\n",
            "FAC :  19\n",
            "CARDINAL-GPE :  18\n",
            "CARDINAL-NORP :  17\n",
            "PERSON-PERSON :  13\n",
            "WORK_OF_ART :  13\n",
            "GPE-ORG :  11\n",
            "PERSON-GPE :  10\n",
            "LAW :  10\n",
            "DATE-EVENT :  9\n",
            "ORG-ORG :  9\n",
            "GPE-GPE :  9\n",
            "LANGUAGE :  7\n",
            "NORP-ORG :  6\n",
            "ORG-GPE :  5\n",
            "DATE-ORG :  5\n",
            "DATE-TIME :  5\n",
            "DATE-NORP :  5\n",
            "ORG-DATE :  5\n",
            "DATE-PERSON :  3\n",
            "PERSON-ORG :  3\n",
            "GPE-ORDINAL :  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwVjyZoHcVEI"
      },
      "source": [
        "> **Extra**: frequency by class number\n",
        "\n",
        "> example: `\"CARDINAL-NORP\"` is built with 2 classes or entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_HYrFVMcxx-",
        "outputId": "06386c0b-ff0c-4ecf-c55e-de01d245ebe1"
      },
      "source": [
        "class_num_freq = defaultdict(lambda:0)\n",
        "for key, value in group_entities_frequency.items():\n",
        "  classes = key.split('-')\n",
        "  class_num_freq[len(classes)] += value\n",
        "\n",
        "print('----- Frequency by number of classes -----')\n",
        "for key, value in class_num_freq.items():\n",
        "  print('Group with ', key, ' class: ', value)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Frequency by number of classes -----\n",
            "Group with  1  class:  7166\n",
            "Group with  2  class:  405\n",
            "Group with  3  class:  20\n",
            "Group with  4  class:  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gvuDb7FYlEn"
      },
      "source": [
        "# **Task 3**: Post-processing \n",
        "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAFgdDwkY8_f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}