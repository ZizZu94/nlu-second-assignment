{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlu-first-assignment.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7eILskklMmtoB/NGPX0zh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ff_g7KO4jncR"},"source":["# **NLU First Assignment** \n","*   **Zihadul Azam**\n","*   Id: 221747\n","*   zihadul.azam@studenti.unitn.it\n","\n","\n","### **Requirements**\n","\n","\n","*   SpaCy: run `pip install spacy`"]},{"cell_type":"code","metadata":{"id":"IstODjTEji7U","executionInfo":{"status":"ok","timestamp":1618832123984,"user_tz":-120,"elapsed":1451,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}}},"source":["example = \"I saw the man with a telescope.\" \n","example_2 = \"I saw a man on a hill with a telescope.\"\n","\n","import spacy\n","\n","nlp = spacy.load('en')"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yi8ZuyZm8om7"},"source":["### Visualize dependency graph with `displacy` (for test)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"viF4BSbD81Zy","executionInfo":{"status":"ok","timestamp":1618832123985,"user_tz":-120,"elapsed":1445,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}},"outputId":"b90674c8-e1e1-4bbf-8fad-308952b8a5e0"},"source":["from spacy import displacy\n","doc = nlp(example)\n","displacy.render(doc, style=\"dep\", jupyter=True, options={'distance': 90})"],"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b67ce7bee2ed4c72b3bc7e70251a1a5e-0\" class=\"displacy\" width=\"680\" height=\"227.0\" direction=\"ltr\" style=\"max-width: none; height: 227.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">saw</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">the</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">man</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">with</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">a</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"137.0\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">telescope.</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NOUN</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-0\" stroke-width=\"2px\" d=\"M70,92.0 C70,47.0 135.0,47.0 135.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,94.0 L62,82.0 78,82.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-1\" stroke-width=\"2px\" d=\"M250,92.0 C250,47.0 315.0,47.0 315.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M250,94.0 L242,82.0 258,82.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-2\" stroke-width=\"2px\" d=\"M160,92.0 C160,2.0 320.0,2.0 320.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M320.0,94.0 L328.0,82.0 312.0,82.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-3\" stroke-width=\"2px\" d=\"M340,92.0 C340,47.0 405.0,47.0 405.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M405.0,94.0 L413.0,82.0 397.0,82.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-4\" stroke-width=\"2px\" d=\"M520,92.0 C520,47.0 585.0,47.0 585.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M520,94.0 L512,82.0 528,82.0\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-5\" stroke-width=\"2px\" d=\"M430,92.0 C430,2.0 590.0,2.0 590.0,92.0\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-b67ce7bee2ed4c72b3bc7e70251a1a5e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M590.0,94.0 L598.0,82.0 582.0,82.0\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"bZPJAgvcleUv"},"source":["## **Function 1:** Extract a path of dependency relations from the ROOT to a token\n","##### **Input:** a sentence (type: string)\n","\n","\n","> Example: `\"I saw the man with a telescope.\"`\n","\n","\n","##### **Output:** for each token the path will be a list of dependency relations, where first element is ROOT (type: dictionary)\n","\n","\n","> Example: `[{'token': 'I', 'path': ['ROOT(saw)', 'nsubj(I)']}, ... ]`\n","\n","\n","\n","\n","---\n","\n","The goal of this function is to find all the paths from the ROOT to the tokens. So, if we have **N words** in the input sentence, the output of this function will be **N paths**.\n","However, I found two solutions:\n","\n","\n","1.   The first one is very handy, I used the **ancestors' list** of the token. SpaCy library provides us a list of ancestors for each token (`token.ancestors` property), but in reverse order (the first token in the list is the nearest ancestor). So, for having the path in top-bottom format (from ROOT to the token) I took each ancestor and pushed `token.dep_`(relation) and `token.text` into a list.\n","2.   The second solution is the classic one, I used the **head** parameter of the token. The function goes up recursively until not find the ROOT. How we can know that the current token is the ROOT token? If **`token.head` is equal to the current token**, then the current token is the ROOT token. However, we can find the ROOT also by using `token.sent.root`.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"X9G0bESI65xI"},"source":["### **Solution 1:** using `token.ancestors`"]},{"cell_type":"code","metadata":{"id":"-KXapKsMlS58","executionInfo":{"status":"ok","timestamp":1618832123986,"user_tz":-120,"elapsed":1439,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}}},"source":["def extract_all_paths_from_root(sentence):\n","  \"\"\"\n","  this function extract dependency path\n","  from the root to each token\n","  \"\"\"\n","  doc = nlp(sentence)\n","  paths = {}\n","\n","  for sent in doc.sents:\n","    for token in sent:\n","      paths[token.i] = {'token': token.text, 'path': extract_path_from_root(token)} #for each token extract path\n","  return paths\n","\n","def extract_path_from_root(token):\n","  \"\"\"\n","  this function extract path from the root\n","  to a token using ancestor list of the token\n","  \"\"\"\n","  path=[\"{}({})\".format(token.dep_, token.text)] #add current token\n","  for ances_token in token.ancestors:\n","      path.insert(0, \"{}({})\".format(ances_token.dep_, ances_token.text)) #push ancestor token info \n","  return path"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhYB4_7_EZml","executionInfo":{"status":"ok","timestamp":1618832124289,"user_tz":-120,"elapsed":1737,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}},"outputId":"4b051e4b-042a-47d6-b183-68d4661a8027"},"source":["res = extract_all_paths_from_root(example)\n","print('---------------------Al paths from ROOT to tokens---------------------')\n","print('Input sentence: ', example)\n","print('----------------------------------------------------------------------')\n","for key in res:\n","  print(res[key])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["---------------------Al paths from ROOT to tokens---------------------\n","Input sentence:  I saw the man with a telescope.\n","----------------------------------------------------------------------\n","{'token': 'I', 'path': ['ROOT(saw)', 'nsubj(I)']}\n","{'token': 'saw', 'path': ['ROOT(saw)']}\n","{'token': 'the', 'path': ['ROOT(saw)', 'dobj(man)', 'det(the)']}\n","{'token': 'man', 'path': ['ROOT(saw)', 'dobj(man)']}\n","{'token': 'with', 'path': ['ROOT(saw)', 'dobj(man)', 'prep(with)']}\n","{'token': 'a', 'path': ['ROOT(saw)', 'dobj(man)', 'prep(with)', 'pobj(telescope)', 'det(a)']}\n","{'token': 'telescope', 'path': ['ROOT(saw)', 'dobj(man)', 'prep(with)', 'pobj(telescope)']}\n","{'token': '.', 'path': ['ROOT(saw)', 'punct(.)']}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bofX-Ra57G7Q"},"source":["### **Solution 2:** using `token.head` (recursive)"]},{"cell_type":"code","metadata":{"id":"d3oGU-Ab7M3c","executionInfo":{"status":"ok","timestamp":1618832124289,"user_tz":-120,"elapsed":1731,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}}},"source":["def extract_all_paths_from_root_rec(sentence):\n","  \"\"\"\n","  this function extract dependency path\n","  from the root to each token using head of the token.\n","  \"\"\"\n","  doc = nlp(sentence)\n","  paths = {}\n","  for sent in doc.sents:\n","    for token in sent:\n","      paths[token.i] = {'token': token.text, 'path': extract_path_from_root_rec(token)} #for each token extract path\n","  return paths\n","\n","def extract_path_from_root_rec(token):\n","  \"\"\"\n","  this function is a recursive function.\n","  recursively go up until find the root\n","  \"\"\"\n","  result = [\"{}({})\".format(token.dep_, token.text)] #add current token\n","  # if this token is root token\n","  if token.head == token:\n","    return result\n","  return extract_path_from_root_rec(token.head) + result # joint ancestor token info with current token info and return"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYRQrdCEEP8S","executionInfo":{"status":"ok","timestamp":1618832124290,"user_tz":-120,"elapsed":1725,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}},"outputId":"44515a36-3feb-414f-83f7-b1175168210a"},"source":["res = extract_all_paths_from_root_rec(example)\n","print('---------------------Al paths from ROOT to tokens (recursive)---------------------')\n","print('Input sentence: ', example)\n","print('----------------------------------------------------------------------------------')\n","for key in res:\n","  print(res[key])"],"execution_count":22,"outputs":[{"output_type":"stream","text":["---------------------Al paths from ROOT to tokens (recursive)---------------------\n","Input sentence:  I saw the man with a telescope.\n","----------------------------------------------------------------------------------\n","{'token': 'I', 'path': ['ROOT(saw)', 'nsubj(I)']}\n","{'token': 'saw', 'path': ['ROOT(saw)']}\n","{'token': 'the', 'path': ['ROOT(saw)', 'dobj(man)', 'det(the)']}\n","{'token': 'man', 'path': ['ROOT(saw)', 'dobj(man)']}\n","{'token': 'with', 'path': ['ROOT(saw)', 'dobj(man)', 'prep(with)']}\n","{'token': 'a', 'path': ['ROOT(saw)', 'dobj(man)', 'prep(with)', 'pobj(telescope)', 'det(a)']}\n","{'token': 'telescope', 'path': ['ROOT(saw)', 'dobj(man)', 'prep(with)', 'pobj(telescope)']}\n","{'token': '.', 'path': ['ROOT(saw)', 'punct(.)']}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dLxwA_nAzu-f"},"source":["## **Function 2:** Extract subtree of a dependents given a token\n","##### **Input:** a sentence\n","\n","\n","> Example: `\"I saw the man with a telescope.\"`\n","\n","\n","##### **Output:** for each token in Doc objects you extract a subtree of its dependents as a list (ordered w.r.t. sentence order)\n","\n","\n","> Example: `[{'token': 'man', 'subtree': ['the', 'with', 'a', 'telescope']}, ...]`\n","\n","\n","---\n","\n","\n","The goal of this function is to find the subtree of its dependents (ordered w.r.t. sentence order). For having the subtree for each token I used `token.subtree` property, which returns: token + its dependents. But, reading carefully the task requirements I interpreted that, the output should contain only the list of its dependents, not the token itself, so I removed the root token (current token) from the subtree with an if condition: `if sub_token is not token`."]},{"cell_type":"code","metadata":{"id":"TLnjGvEdz6Lu","executionInfo":{"status":"ok","timestamp":1618832124291,"user_tz":-120,"elapsed":1719,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}}},"source":["def get_subtree_of_a_token(token):\n","  return [sub_token.text for sub_token in token.subtree if sub_token is not token] #return subtree without root\n","\n","def extract_subtree(sentence):\n","  doc = nlp(sentence)\n","  result = {}\n","\n","  for sent in doc.sents:\n","    for token in sent:\n","      result[token.i] = {'token': token.text, 'subtree': get_subtree_of_a_token(token)}\n","  return result"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SU1V52GmoiA9","executionInfo":{"status":"ok","timestamp":1618832124292,"user_tz":-120,"elapsed":1714,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}},"outputId":"b36d61a4-d09f-477d-a811-5f856edbcb5c"},"source":["res = extract_subtree(example)\n","print('---------------------Subtree for each tokens---------------------')\n","print('Input sentence: ', example,)\n","print('-----------------------------------------------------------------')\n","for key in res:\n","  print(res[key])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["---------------------Subtree for each tokens---------------------\n","Input sentence:  I saw the man with a telescope.\n","-----------------------------------------------------------------\n","{'token': 'I', 'subtree': []}\n","{'token': 'saw', 'subtree': ['I', 'the', 'man', 'with', 'a', 'telescope', '.']}\n","{'token': 'the', 'subtree': []}\n","{'token': 'man', 'subtree': ['the', 'with', 'a', 'telescope']}\n","{'token': 'with', 'subtree': ['a', 'telescope']}\n","{'token': 'a', 'subtree': []}\n","{'token': 'telescope', 'subtree': ['a']}\n","{'token': '.', 'subtree': []}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XPJr5l5oAaA2"},"source":["## **Function 3:** Check if a given list of tokens (segment of a sentence) forms a subtree\n","##### **Input:** a sentence | ordered list of words from a sentence\n","\n","\n","> Example sentence: `\"I saw the man with a telescope.\"`\n","\n","> Example token list: `['a', 'telescope']`\n","\n","\n","##### **Output:** True/False based on the sequence forming a subtree or not\n","\n","\n","> Example: True\n","\n","\n","---\n","\n","\n","\n","The goal of this function is, given a sentence and a segment of sentence (list of tokens), find if the segment forms a subtree or not. \n","\n","To find whether it forms or not, first, we have to take the input sentence and find all dependency subtrees (for each token). I could have used **function number 2** to get all subtrees, but It does not include the root token (due to specific requirement) when returning a subtree. So, here I implemented a new function that includes also the root token when return a subtree (used `token.subtree` property). \n","\n","Once, we have all the subtrees we can compare them with our input token list (sentence segment). To compare two lists I used `if list1 == list2`."]},{"cell_type":"code","metadata":{"id":"jfSHU8K8CVAc","executionInfo":{"status":"ok","timestamp":1618832124292,"user_tz":-120,"elapsed":1708,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}}},"source":["def is_subtree(sentence, tokens=[]):\n","  trees = extract_subtree_with_root(sentence)\n","  for key in trees:\n","    if trees[key]['subtree'] == tokens:\n","      return True\n","  return False\n","\n","def extract_subtree_with_root(sentence):\n","  doc = nlp(sentence)\n","  result = {}\n","\n","  for sent in doc.sents:\n","    for token in sent:\n","      sub_tree = [sub_token.text for sub_token in token.subtree]\n","      result[token.i] = {'token': token.text, 'subtree': sub_tree}\n","  return result"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BHpt_CGppzpU","executionInfo":{"status":"ok","timestamp":1618832124493,"user_tz":-120,"elapsed":1904,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}},"outputId":"639dd6e2-43cc-4fc2-8b33-91552dbbe277"},"source":["print('---------------------Check if a given list of tokens forms a subtree---------------------')\n","print('Input sentence: ', example,)\n","print('-----------------------------------------------------------------------------------------')\n","seg_sent = ['a', 'telescope']\n","seg_sent_str = ' '.join(seg_sent)\n","print('Test 1 with segment of token: ', seg_sent)\n","print('Is <', seg_sent_str, '> form a subtree?: ', is_subtree(example, seg_sent))\n","print('-----------------------------------------------------------------------------------------')\n","seg_sent = ['telescope', 'a']\n","seg_sent_str = ' '.join(seg_sent)\n","print('Test 2 with segment of token: ', seg_sent)\n","print('Is <', seg_sent_str, '> form a subtree?: ', is_subtree(example, seg_sent))\n","print('-----------------------------------------------------------------------------------------')\n","seg_sent = ['I', 'the', 'saw', 'man']\n","seg_sent_str = ' '.join(seg_sent)\n","print('Test 2 with segment of token: ', seg_sent)\n","print('Is <', seg_sent_str, '> form a subtree?: ', is_subtree(example, seg_sent))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["---------------------Check if a given list of tokens forms a subtree---------------------\n","Input sentence:  I saw the man with a telescope.\n","-----------------------------------------------------------------------------------------\n","Test 1 with segment of token:  ['a', 'telescope']\n","Is < a telescope > form a subtree?:  True\n","-----------------------------------------------------------------------------------------\n","Test 2 with segment of token:  ['telescope', 'a']\n","Is < telescope a > form a subtree?:  False\n","-----------------------------------------------------------------------------------------\n","Test 2 with segment of token:  ['I', 'the', 'saw', 'man']\n","Is < I the saw man > form a subtree?:  False\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v0o9pX7VUU38"},"source":["## **Function 4:** Identify head of a span, given its tokens \n","##### **Input:** Span - is a sequence of words (not necessarily a sentence)\n","\n","\n","> Example: `'a man with a telescope'`\n","\n","\n","##### **Output:** the head of the span (single word)\n","\n","\n","> Example: `'man'`\n","\n","\n","---\n","\n","This function returns the **head of a span**. To find the head token we have to find the token which links itself as the head. So we iterate over all tokens and return token `if token.head == token`.\n"]},{"cell_type":"code","metadata":{"id":"NP-UvJFpfzgC","executionInfo":{"status":"ok","timestamp":1618832124493,"user_tz":-120,"elapsed":1898,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}}},"source":["def get_head_of_span(span):\n","  doc = nlp(span)\n","  for sent in doc.sents:\n","    for token in sent:\n","      if token.head == token:\n","        return token.text\n","  return None"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TtV_L-ayq0mZ","executionInfo":{"status":"ok","timestamp":1618832124911,"user_tz":-120,"elapsed":2311,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}},"outputId":"a69c3775-1b2a-4842-f100-7e90460deb60"},"source":["print('---------------------Identify head of a span---------------------')\n","span = 'a man with a telescope'\n","print('Head of span <', span, '> is: ', get_head_of_span(span))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["---------------------Identify head of a span---------------------\n","Head of span < a man with a telescope > is:  man\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k19frUK3rHpZ"},"source":["## **Function 5:** Extract sentence subject, direct object and indirect object spans \n","##### **Input:** a sequence\n","\n","\n","> Example: `\"I saw the man with a telescope.\"`\n","\n","\n","##### **Output:**  lists of words that form a span (not a single word) for subject, direct object, and indirect object (if present of course, otherwise empty) - Type: dict of lists\n","\n","\n","> Example: `nsubj :\t ['I']` `dobj :\t ['man']` `dative :\t []`\n","\n","\n","---\n","\n","This functions returns a dictionary with three lists:\n","\n","\n","1.   **Subject token list**: includes all the subject tokens of the input sentence. A token is a subject `if token.dep_ == 'nsubj'`\n","2.   **Direct object list**: includes all the direct object tokens of the input sentence. A token is a direct object `if token.dep_ == 'dobj'`\n","3.   **Indirect object list**: include all the indirect object tokens of the input sentence. A token is a indirect object `if token.dep_ == 'dative'`\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"orUKPMTYriZN","executionInfo":{"status":"ok","timestamp":1618832124915,"user_tz":-120,"elapsed":2309,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}}},"source":["def extract_S_DO_IO(sentence):\n","  doc = nlp(sentence)\n","\n","  subject_tag = 'nsubj'\n","  direct_obj_tag = 'dobj'\n","  indirect_obj_tag = 'dative'\n","  filter_tags = [subject_tag, direct_obj_tag, indirect_obj_tag]\n","\n","  result = {\n","      subject_tag: [],\n","      direct_obj_tag: [],\n","      indirect_obj_tag: [],\n","  }\n","\n","  for sent in doc.sents:\n","    for token in sent:\n","      if token.dep_ in filter_tags:\n","        result[token.dep_].append(token.text)\n","  return result"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLZK1LK0rU_l","executionInfo":{"status":"ok","timestamp":1618832124917,"user_tz":-120,"elapsed":2306,"user":{"displayName":"Zihadul Azam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhGP-jUgaopGdRYRSj66kKcncRJmqr7r5PGHMGN=s64","userId":"16607962773620346222"}},"outputId":"04d781f4-ed41-47a3-bd57-a40129f2a217"},"source":["print('---------------------Extract sentence subject, direct object and indirect object spans---------------------')\n","print('Test 1')\n","res = extract_S_DO_IO(example)\n","print('Subject, direct object, and indirect object of the sentence: <', example,'>')\n","for key in res:\n","  print(key, ':\\t', res[key])\n","print('-----------------------------------------------------------------------------------------')\n","example = 'Give the book to me.'\n","print('Test 2')\n","res = extract_S_DO_IO(example)\n","print('Subject, direct object, and indirect object of the sentence: <', example,'>')\n","for key in res:\n","  print(key, ':\\t', res[key])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["---------------------Extract sentence subject, direct object and indirect object spans---------------------\n","Test 1\n","Subject, direct object, and indirect object of the sentence: < I saw the man with a telescope. >\n","nsubj :\t ['I']\n","dobj :\t ['man']\n","dative :\t []\n","-----------------------------------------------------------------------------------------\n","Test 2\n","Subject, direct object, and indirect object of the sentence: < Give the book to me. >\n","nsubj :\t []\n","dobj :\t ['book']\n","dative :\t ['to']\n"],"name":"stdout"}]}]}